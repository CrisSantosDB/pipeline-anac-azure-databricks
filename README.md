# âœˆï¸ Transformando Dados de OcorrÃªncias AÃ©reas em Insights Regionais com Databricks

Transformei dados brutos da **ANAC** em uma base de dados analÃ­tica, limpa e confiÃ¡vel, utilizando **Azure Data Lake**, **Databricks** (com PySpark) e arquitetura de dados moderna com **Bronze, Silver e Gold**.





## Arquitetura da SoluÃ§Ã£o

<p align="center">
  <img src="https://raw.githubusercontent.com/CrisSantosDB/pipeline-anac-azure-databricks/main/medalhao.jpg" width="800"/>
</p>






---

## ğŸ’¼ Objetivo de NegÃ³cio

Reduzir o tempo gasto por analistas estaduais com limpeza e preparaÃ§Ã£o de dados sobre **ocorrÃªncias aÃ©reas no Brasil**, oferecendo uma base final intuitiva e pronta para anÃ¡lise â€” com destaque para a **ocorrÃªncia de lesÃµes por Estado (UF)**.

---

## âš™ï¸ Tecnologias Usadas

- **Azure Storage (Data Lake Gen2)**
- **Azure Databricks (PySpark)**
- **Arquitetura em camadas (Bronze / Silver / Gold)**

---

## ğŸ§± Arquitetura do Projeto

### ğŸŸ« Bronze â€“ Dados Brutos
ImportaÃ§Ã£o direta do dataset `V_OCORRENCIA_AMPLA.json` da ANAC. Nenhuma transformaÃ§Ã£o aplicada.

---

### ğŸŸª Silver â€“ Dados Tratados
- Preenchimento de valores nulos com `"Sem Registro"` para colunas de texto.
- ConversÃ£o de colunas numÃ©ricas (relacionadas a lesÃµes) de string para inteiro.
- Preenchimento de nulos com `0` nessas colunas.
- Salvamento no formato **Parquet**, pronto para agregaÃ§Ãµes e filtros.

> ğŸ’¡ Resultado: dados estruturados e tipados, com consistÃªncia de valores faltantes.

---

### ğŸŸ¨ Gold â€“ Base Final para AnÃ¡lise
- SeleÃ§Ã£o apenas das colunas solicitadas pelos analistas.
- CriaÃ§Ã£o da coluna `Total_Lesoes` com a soma de todas as lesÃµes (fatais, graves, leves, desconhecidas).
- RenomeaÃ§Ã£o das colunas para nomes mais simples e intuitivos.
- Filtro para remover Estados com classificaÃ§Ã£o "Indeterminado", "Sem Registro" e "Exterior".
- AdiÃ§Ã£o da coluna `Atualizacao` com data/hora da atualizaÃ§Ã£o (timezone: SÃ£o Paulo).
- Escrita em Parquet particionado por `Estado (UF)` para melhorar performance de leitura.

> âœ… Base final simples, intuitiva e pronta para dashboards ou anÃ¡lises com Power BI, Synapse ou ferramentas de BI.

---

## ğŸ“ˆ Impacto de NegÃ³cio

- **ReduÃ§Ã£o de +70%** no tempo de preparaÃ§Ã£o dos dados pelos analistas estaduais.
- EliminaÃ§Ã£o de dados invÃ¡lidos e inconsistentes.
- CriaÃ§Ã£o de uma mÃ©trica-chave: **Total de LesÃµes por OcorrÃªncia**, facilitando a priorizaÃ§Ã£o de investigaÃ§Ãµes.
- **OrganizaÃ§Ã£o por Estado** permite anÃ¡lises regionais imediatas.
---
## âš™ï¸ Pipeline no Azure Data Factory (ADF)

- Uma pipeline simples foi criada com o Azure Data Factory com o objetivo de praticar a orquestraÃ§Ã£o de processos no ambiente Azure.
- Embora o processamento principal tenha sido feito diretamente no Databricks, a inclusÃ£o do ADF mostra a possibilidade de integraÃ§Ã£o entre os serviÃ§os e reforÃ§a minha familiaridade com ferramentas de orquestraÃ§Ã£o em nuvem.
---
## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

â”œâ”€â”€ Anac/                           # Dados utilizados no projeto


â”œâ”€â”€ Notebooks - Desenvolvimento/   # Notebooks usados para testes e desenvolvimento inicial


â”œâ”€â”€ Notebooks - ProduÃ§Ã£o/          # VersÃµes finais dos notebooks utilizados em produÃ§Ã£o


â”œâ”€â”€ pipeline/                      # Pipeline criada com Azure Data Factory para orquestraÃ§Ã£o de testes no fluxo de dados


â”œâ”€â”€ trigger/                       # Trigger de agendamento para a execuÃ§Ã£o da pipeline


â”œâ”€â”€ README.md                      # DocumentaÃ§Ã£o do projeto


â”œâ”€â”€ publish_config.json           # ConfiguraÃ§Ãµes de publicaÃ§Ã£o do ADF




